{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd68bd-46c4-4c9a-a0c7-4db9ca7cf6f4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "12dd68bd-46c4-4c9a-a0c7-4db9ca7cf6f4",
    "outputId": "451326eb-3f6b-4296-8efc-0cac16d5e674"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "import os\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from scipy import stats\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960488e-c6fd-4854-be3f-a2da626433ca",
   "metadata": {
    "id": "f960488e-c6fd-4854-be3f-a2da626433ca"
   },
   "outputs": [],
   "source": [
    "# config\n",
    "\n",
    "MODEL_PATH =  'model/changenet_trained_weights.pth' \n",
    "DATA_PATH = 'data/toy_dataset_site.hdf5'\n",
    "SITE_LIST = ['CCR5_s8', 'LAG3_s9', 'TRAC_s1', 'CTLA4_s9', 'AAVS1_s14']\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "NUM_EPOCHS = 300\n",
    "gRNA = {'AAVS1_s14': 'GGGGCCACTAGGGACAGGATTGG',\n",
    "        'CTLA4_s9': 'GGACTGAGGGCCATGGACACGGG',\n",
    "        'TRAC_s1': 'GTCAGGGTTCTGGATATCTGTGG',\n",
    "        'LAG3_s9': 'GAAGGCTGAGATCCTGGAGGGGG',\n",
    "        'CXCR4_s8': 'GTCCCCTGAGCCCATTTCCTCGG',\n",
    "        'CCR5_s8': 'GGACAGTAAGAAGGAAAAACAGG'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vyi9bdwzIqSc",
   "metadata": {
    "id": "vyi9bdwzIqSc"
   },
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956d69e1-adc9-4b9a-9e80-7c578c4157b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "956d69e1-adc9-4b9a-9e80-7c578c4157b6",
    "outputId": "7a8f1ef6-c2bb-4fc0-e3d8-ba1671770081"
   },
   "outputs": [],
   "source": [
    "# Loading dataset\n",
    "class SeqData(Dataset):\n",
    "    def __init__(self, X, seq=None):\n",
    "        self.X = X\n",
    "        self.seq = seq\n",
    "        self.length = len(self.X)\n",
    "\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        X = torch.tensor(self.X[i], dtype=torch.float32)\n",
    "        return X\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.length\n",
    "\n",
    "\n",
    "print('Loading dataset...')\n",
    "X = []\n",
    "seq = []\n",
    "mismatches = []\n",
    "len_list = []\n",
    "source_site = []\n",
    "\n",
    "for site in SITE_LIST:\n",
    "    data_path = DATA_PATH.replace('site', site)\n",
    "    with h5py.File(data_path, 'r') as f:\n",
    "        for num_mismatches in range(0, 7):\n",
    "            X_s = np.array(f[str(num_mismatches)]['X']).astype(np.float32)\n",
    "            X_s[:,20,:4] = 0.25 # Set the first base of PAM to N\n",
    "            seq_s = np.array(f[str(num_mismatches)]['seq']).astype(str)\n",
    "\n",
    "            X.append(X_s)\n",
    "            seq.append(seq_s)\n",
    "            mismatches.append([num_mismatches] * len(X_s))\n",
    "            source_site.append([site] * len(X_s))\n",
    "            print(num_mismatches, X_s.shape)\n",
    "            len_list.append(len(X_s))\n",
    "            del X_s, seq_s\n",
    "\n",
    "X = np.concatenate(X)\n",
    "seq = np.concatenate(seq)\n",
    "mismatches = np.concatenate(mismatches)\n",
    "source_site = np.concatenate(source_site)\n",
    "\n",
    "print(X.shape, mismatches.shape, source_site.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c325b12-ca2f-4b58-9017-3184bb4911a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7c325b12-ca2f-4b58-9017-3184bb4911a5",
    "outputId": "48bf3411-ed69-4aba-b026-40666cf3ca52"
   },
   "outputs": [],
   "source": [
    "dts = SeqData(X, seq)\n",
    "\n",
    "loader_test = DataLoader(dataset = dts, \\\n",
    "                        batch_size = 8192,\\\n",
    "                        pin_memory=True,\\\n",
    "                        num_workers = 0,\\\n",
    "                        shuffle = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb69102e-2f81-48cc-b027-9df25a2044f0",
   "metadata": {},
   "source": [
    "## Loading trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f403c93-cd2e-4e77-a559-55b29efa54eb",
   "metadata": {
    "id": "2f403c93-cd2e-4e77-a559-55b29efa54eb"
   },
   "outputs": [],
   "source": [
    "def get_free_gpu():\n",
    "    os.system('nvidia-smi -q -d Memory |grep -A5 GPU|grep Free > ./tmp')\n",
    "    memory_available = [int(x.split()[2]) for x in open('tmp', 'r').readlines()]\n",
    "    return int(np.argmax(memory_available))\n",
    "\n",
    "# id = get_free_gpu()\n",
    "# device = torch.device(\"cuda:%d\" % id)\n",
    "device = 'cpu'\n",
    "\n",
    "class CHANGENET(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.ModuleList()\n",
    "        dropout = 0.2\n",
    "        hidden_dim = 128\n",
    "\n",
    "        self.seq_length = 23\n",
    "        self.layers.append(nn.Conv1d(in_channels = 8, out_channels = hidden_dim, kernel_size = 3, padding = 1))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_dim, track_running_stats = True))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels = hidden_dim, out_channels = hidden_dim, kernel_size = 3, padding = 1))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_dim, track_running_stats = True))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels = hidden_dim, out_channels = hidden_dim, kernel_size = 3, padding = 1))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_dim, track_running_stats = True))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels = hidden_dim, out_channels = hidden_dim, kernel_size = 5, padding = 2))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_dim, track_running_stats = True))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels = hidden_dim, out_channels = hidden_dim, kernel_size = 5, padding = 2))\n",
    "        self.layers.append(nn.BatchNorm1d(hidden_dim, track_running_stats = True))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Conv1d(in_channels = hidden_dim, out_channels = 10, kernel_size = 5, padding = 2))\n",
    "        self.layers.append(nn.BatchNorm1d(10, track_running_stats = True))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Dropout(dropout))\n",
    "\n",
    "        self.layers.append(nn.Flatten())\n",
    "\n",
    "        self.layers.append(nn.Linear(self.seq_length * 10, 128))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Linear(128, 32))\n",
    "        self.layers.append(nn.LeakyReLU())\n",
    "        self.layers.append(nn.Linear(32, 1))\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x\n",
    "        for layer in self.layers:\n",
    "            out = layer(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = CHANGENET()\n",
    "model.to(device)\n",
    "mseloss = nn.MSELoss()\n",
    "checkpoint = torch.load(MODEL_PATH)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20289b81-cd51-4893-9165-452bd5414bf1",
   "metadata": {},
   "source": [
    "## Running inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea06695b-8efa-4eba-8e44-48a786f7e9a6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ea06695b-8efa-4eba-8e44-48a786f7e9a6",
    "outputId": "ab41ccd8-b068-4544-bde3-89dcb89a1f38"
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "pred_list = []\n",
    "\n",
    "for i, X in enumerate(loader_test):\n",
    "    X  = X.to(device)\n",
    "    X = torch.transpose(X, 1, 2)\n",
    "    output = model(X)\n",
    "    pred_list.append(output.cpu().detach().numpy().reshape(-1,))\n",
    "\n",
    "pred_list = np.concatenate(pred_list)\n",
    "\n",
    "d = {'seq': seq,\n",
    "     'gRNA': source_site,\n",
    "     'mismatches': mismatches,\n",
    "     'gRNA_seq': [gRNA[s] for s in source_site],\n",
    "     'log2FC_pred': pred_list\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data=d)\n",
    "if not os.path.exists('results/'):\n",
    "    os.mkdir('results/')\n",
    "df.to_csv('results/prediction_results_toy_dataset.csv')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fec5bd-ed89-4a0d-80ef-5a9e1e832385",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
